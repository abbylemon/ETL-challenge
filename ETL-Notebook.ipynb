{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Abbys section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end Abbys section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Umar section\n",
    "\n",
    "#File path to read it in as a data frame \n",
    "file = \"directory.csv\"\n",
    "\n",
    "#Dataframe\n",
    "Starbucks = pd.read_csv(file)\n",
    "Starbucks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the countries in the data we don't need \n",
    "New_data = Starbucks.Country == \"US\"\n",
    "Starbucks = Starbucks[New_data]\n",
    "\n",
    "#Now drop the columns we don't need\n",
    "Final_data = Starbucks.drop(['Brand', 'Store Name', 'Ownership Type', 'Country', 'Phone Number', 'Timezone', 'Longitude', 'Latitude'], axis=1)\n",
    "Final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the store number as your index & rename the column\n",
    "#Starbucks_count = Final_data.set_index(\"Store Number\")\n",
    "Starbucks_table = Final_data.rename(columns={\"State/Province\": \"state\", \"Store Number\": \"store_number\",\n",
    "                                                  \"Street Address\": \"street_address\",\"City\": \"city\",\n",
    "                                                  \"Postcode\": \"postcode\"})\n",
    "New = Starbucks_table.dropna()\n",
    "New.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the DataType to set-up for merge with SQL\n",
    "#Postcode_df = New[columns(['Postcode'].str[:5]]\n",
    "New[\"postcode\"] = New['postcode'].str[:5]\n",
    "New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting \n",
    "#df.astype({'col1': 'int32'}).dtypes\n",
    "Casting = New.astype({'postcode': 'int32'}).dtypes\n",
    "Casting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a database connection\n",
    "engine = create_engine('postgresql://postgres:friend01@localhost:5432/store_locations_db')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the connection\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframe into SQL database\n",
    "\n",
    "New.to_sql(name='starbucks_locations', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end Umar section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
