{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing in Target Location file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from the csv file downloaded from Kaggle\n",
    "\n",
    "target_df = pd.read_csv('target.csv', encoding='utf-8')\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# down select the columns of interest\n",
    "\n",
    "removecolumns_target_df = target_df[['ID', 'Address.AddressLine1', 'Address.City', 'Address.PostalCode', 'Address.Subdivision']]\n",
    "removecolumns_target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column headers\n",
    "\n",
    "renamed_target_df = removecolumns_target_df.rename(columns={\n",
    "    'ID': 'target_store_id',\n",
    "    'Address.AddressLine1': 'street_address',\n",
    "    'Address.City': 'city',\n",
    "    'Address.PostalCode': 'zip_code',\n",
    "    'Address.Subdivision': 'state_abr'\n",
    "})\n",
    "renamed_target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the zip code column to match the other files zip code formats\n",
    "\n",
    "renamed_target_df['striped_zip'] = renamed_target_df['zip_code'].str.split('-', n = 1, expand = True)[0]\n",
    "\n",
    "newzip_target_df = renamed_target_df.drop(columns=('zip_code'))\n",
    "newzip_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connected to the sql database\n",
    "\n",
    "rds_connection_string = \"postgres:postgres@localhost:5432/store_locations_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the connection\n",
    "\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the transformed dataset to the database\n",
    "\n",
    "newzip_target_df.to_sql(name=\"target_locations\", con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to validate that the data loaded to the database\n",
    "\n",
    "pd.read_sql_query('select * from target_locations', con=engine).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringin in Starbucks Menu file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from a csv downloaded from Kaggle\n",
    "\n",
    "starbucks_menu = pd.read_csv('starbucks_drinkMenu_expanded.csv', encoding='utf-8')\n",
    "starbucks_menu.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a view of the data\n",
    "\n",
    "starbucks_menu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the column headers\n",
    "\n",
    "original_column_titles = list(starbucks_menu.columns.values)\n",
    "original_column_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted characters from the column headers\n",
    "\n",
    "clean_column_titles = []\n",
    "\n",
    "for column in original_column_titles:\n",
    "    columnLower = column.lower()\n",
    "    columnSpace = columnLower.strip()\n",
    "    columnPercent = columnSpace.replace('%',\"\")\n",
    "    columnOpen = columnPercent.replace(\"(\", \"\")\n",
    "    columnClose = columnOpen.replace(\")\", \"\")\n",
    "#     columnDoubleSpace = columnClose.replace(\"  \", \"\")\n",
    "    columnUnderscore = columnClose.replace(\" \", \"_\")\n",
    "    columnDouble = columnUnderscore.replace(\"__\", \"_\")\n",
    "    \n",
    "    clean_column_titles.append(columnDouble)\n",
    "    \n",
    "clean_column_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictonary of the unedited column list and the new column list\n",
    "\n",
    "column_dict = dict(zip(original_column_titles,clean_column_titles))\n",
    "column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dataframe column headers with the dictionary above\n",
    "\n",
    "menu_cleaned_df = starbucks_menu.rename(columns=column_dict)\n",
    "menu_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the transformed data to the database\n",
    "\n",
    "menu_cleaned_df.to_sql(name=\"starbucks_menu\", con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see that the data loaded to the table\n",
    "\n",
    "pd.read_sql_query('select * from starbucks_menu', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File path to read it in as a data frame \n",
    "file = \"directory.csv\"\n",
    "\n",
    "#Dataframe\n",
    "Starbucks = pd.read_csv(file)\n",
    "Starbucks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the countries in the data we don't need \n",
    "New_data = Starbucks.Country == \"US\"\n",
    "Starbucks = Starbucks[New_data]\n",
    "\n",
    "#Now drop the columns we don't need\n",
    "Final_data = Starbucks.drop(['Brand', 'Store Name', 'Ownership Type', 'Country', 'Phone Number', 'Timezone', 'Longitude', 'Latitude'], axis=1)\n",
    "Final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the store number as your index & rename the column\n",
    "#Starbucks_count = Final_data.set_index(\"Store Number\")\n",
    "Starbucks_table = Final_data.rename(columns={\"State/Province\": \"state\", \"Store Number\": \"store_number\",\n",
    "                                                  \"Street Address\": \"street_address\",\"City\": \"city\",\n",
    "                                                  \"Postcode\": \"postcode\"})\n",
    "New = Starbucks_table.dropna()\n",
    "New.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the DataType to set-up for merge with SQL\n",
    "#Postcode_df = New[columns(['Postcode'].str[:5]]\n",
    "New[\"postcode\"] = New['postcode'].str[:5]\n",
    "New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Casting \n",
    "#df.astype({'col1': 'int32'}).dtypes\n",
    "Casting = New.astype({'postcode': 'int32'}).dtypes\n",
    "Casting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a database connection\n",
    "engine = create_engine('postgresql://postgres:friend01@localhost:5432/store_locations_db')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the connection\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframe into SQL database\n",
    "\n",
    "New.to_sql(name='starbucks_locations', con=engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
